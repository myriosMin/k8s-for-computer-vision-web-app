# xBD with YOLO + K8S

## Project Directory

```
.
├── Makefile                  # Automation commands for build, deploy, jobs
├── README.md                 # Project overview and instructions
├── data                      # Datasets and YOLO-formatted data; put aiad_data.zip and test.zip here
│   ├── aiad_data.zip         # Raw dataset archive
│   ├── test.zip              # Test dataset archive
│   └── yolo_xbd              # Preprocessed YOLO data; contents are generated by code
│       ├── images            # train/val/test image folders
│       ├── labels            # train/val/test annotation files
│       ├── test_pairs.csv    # Pre/post image mapping for test set
│       ├── train_pairs.csv   # Pre/post image mapping for training set
│       ├── val_pairs.csv     # Pre/post image mapping for validation set
│       └── xbd6.yaml         # YOLO dataset configuration
├── docker-cmd-sketch.txt     # Draft Docker run commands
├── images                    # Docker image source codes and build contexts
│   ├── infer                 # Inference API container
│   │   ├── Dockerfile
│   │   ├── app/infer_api.py  # FAST API
│   │   └── requirements.txt
│   ├── ui                    # UI container
│   │   ├── Dockerfile
│   │   ├── app/app.py        # Flask backend
│   │   ├── static/css        # Tailwind config & styles
│   │   ├── static/js/app.js  # Frontend JS
│   │   ├── templates         # HTML templates
│   │   └── wsgi.py
│   │   └── requirements.txt
│   └── worker                # Preprocessing & training container
│       ├── Dockerfile
│       ├── app/common.py     # Common datasets
│       ├── app/preprocess.py # Preprocessing from xBD to YOLO format
│       ├── app/train.py      # YOLO multi-class detection training
│       └── requirements.txt
├── k8s                       # Kubernetes manifests & kustomize configs
│   ├── base                   # Base configs
│   │   ├── configmap-app.yaml
│   │   ├── deploy-infer.yaml
│   │   ├── deploy-ui.yaml
│   │   ├── ingress.yaml
│   │   ├── job-preprocess.yaml
│   │   ├── job-train.yaml
│   │   ├── kustomization.yaml
│   │   ├── namespace.yaml
│   │   ├── pvc-datasets.yaml
│   │   ├── pvc-models.yaml
│   │   ├── secret-app.yaml
│   │   ├── svc-infer.yaml
│   │   └── svc-ui.yaml
│   └── dev                    # Dev overlay configs
│       └── kustomization.yaml
├── models                    # Trained model weights; put best.pt here
│   └── best.pt
├── output                    # Inference results and processed output
│   ├── predictions           # Real-time inferences
│   └── yolo_xbd_6ch          # Model training outputs
└── scripts                   # Development utility scripts
    ├── dev_minikube_env.sh
    └── tailwind_build.sh
```

# Quickstart (Essentials)

### What You Need to Fill In
* Put `aiad_data.zip` under `/data` which includes raw xBD data, partially or full.
* Put `best.pt` under `/models` to skip model training and do fine-tuning or inferencing.
* Adjust epochs and pvc sizes as per your intended data input and storage restrictions.

### 0. One-Shot Setup (Recommended)

For the full pipeline — start Minikube, enable addons, build images, deploy, wait for pods, and print the UI URL — run:

```bash
make all
```

(*`make all` is an alias for `make init` in the Makefile.*)

---

### 1. Start Minikube and Enable Addons

```bash
make up
make addons
```

### 2. Build Images Inside Minikube's Docker

```bash
make build
```

### 3. Deploy Everything (Namespace, PVCs, UI, Inference, Ingress)

```bash
make deploy
```

### 4. Add Host Entry

Usually unnecessary: `app.localtest.me` resolves to `127.0.0.1` already.

### 5. Open UI

```bash
make ui
# then browse http://app.localtest.me
```

### 6. Upload and Train

Upload raw **xBD** files on the **"Data & Training"** page. Then run:

```bash
make job-preprocess
make job-train   # trains, saves runs and best.pt under /models
```

### 7. Link Trained Weights to Inference Deployment

Inference uses a fixed `/models/best.pt`. If it’s missing, it pulls a base `yolo11n-seg` model.

**Simplest:** Bind the models PVC to both training and inference (already set). After training, copy/rename the desired `best.pt` to `/models/best.pt` in the PVC.

```bash
kubectl -n xview rollout restart deploy/infer
```

### 8. Run Inference from UI

On the **"Inference"** page, upload a single image. The UI calls `infer:9000/predict` and displays detections with an overlay.

---

### Notes on GPU in Minikube

* If using Windows + WSL2 + Docker Desktop with NVIDIA enabled:

  * Enable GPU in Docker Desktop: *Settings → Resources → GPU*
  * Start Minikube with GPU:

    ```bash
    minikube start --driver=docker --gpu
    ```
  * Install NVIDIA device plugin (optional; may be flaky in Minikube)
* If no GPU, training jobs ignore GPU limits and fall back to CPU (`torch.cuda.is_available()` check in place). *Consider reducing epochs in configmap-app.yaml for testing purposes*.

---
